{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is where we will specifically put all code and answers for our first analysis question\n",
    "\n",
    "## Question: How do fluctuations in unemployment rates across various demographic groups correlate with the performance of the S&P 500 index?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is all imports needed to run our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import ttest_ind\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the web-scraping element needed for our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()\n",
    "browser.get(\"https://www.bls.gov/charts/employment-situation/civilian-unemployment-rate.htm\")\n",
    "browser.maximize_window()\n",
    "wait = WebDriverWait(browser, 15)\n",
    "show_table_button = wait.until(\n",
    "    EC.element_to_be_clickable((By.LINK_TEXT, \"Show table\"))\n",
    ")\n",
    "\n",
    "show_table_button.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "table = browser.find_element(By.TAG_NAME, \"table\")\n",
    "rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "month_years, total_rates, men_rates, women_rates, teen_rates, white_rates, black_rates, asian_rates, latino_rates = ([] for _ in range(9))\n",
    "\n",
    "for row in rows[1:]:\n",
    "    cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    if len(cols) == 8:\n",
    "        th = row.find_element(By.TAG_NAME, \"th\")\n",
    "        month_year = th.find_element(By.CLASS_NAME, \"sub0\").text\n",
    "        month_years.append(month_year)\n",
    "        total_rates.append(cols[0].text)\n",
    "        men_rates.append(cols[1].text)\n",
    "        women_rates.append(cols[2].text)\n",
    "        teen_rates.append(cols[3].text)\n",
    "        white_rates.append(cols[4].text)\n",
    "        black_rates.append(cols[5].text)\n",
    "        asian_rates.append(cols[6].text)\n",
    "        latino_rates.append(cols[7].text)\n",
    "        unemployment_df = pd.DataFrame({\n",
    "    \"Date\": month_years,\n",
    "    \"Total Rate\": total_rates,\n",
    "    \"Male Rate\": men_rates,\n",
    "    \"Female Rate\": women_rates,\n",
    "    \"Teen Rate\": teen_rates,\n",
    "    \"White Rate\": white_rates,\n",
    "    \"Black Rate\": black_rates,\n",
    "    \"Asian Rate\": asian_rates,\n",
    "    \"Hispanic Rate\": latino_rates\n",
    "})\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "print(unemployment_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four cells below are reading and formatting the DataFrames and then merging the two so that we can do our analysis questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_df = pd.read_csv(\"spy.csv\")\n",
    "sp500_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_df[\"Date\"] = pd.to_datetime(unemployment_df[\"Date\"]).dt.strftime('%b %Y')\n",
    "unemployment_df[\"Total Rate\"] = pd.to_numeric(unemployment_df[\"Total Rate\"], errors='coerce')\n",
    "unemployment_df[\"Male Rate\"] = pd.to_numeric(unemployment_df[\"Male Rate\"], errors='coerce')\n",
    "unemployment_df[\"Female Rate\"] = pd.to_numeric(unemployment_df[\"Female Rate\"], errors='coerce')\n",
    "unemployment_df[\"Teen Rate\"] = pd.to_numeric(unemployment_df[\"Teen Rate\"], errors='coerce')\n",
    "unemployment_df[\"White Rate\"] = pd.to_numeric(unemployment_df[\"White Rate\"], errors='coerce')\n",
    "unemployment_df[\"Black Rate\"] = pd.to_numeric(unemployment_df[\"Black Rate\"], errors='coerce')\n",
    "unemployment_df[\"Asian Rate\"] = pd.to_numeric(unemployment_df[\"Asian Rate\"], errors='coerce')\n",
    "unemployment_df[\"Hispanic Rate\"] = pd.to_numeric(unemployment_df[\"Hispanic Rate\"], errors='coerce')\n",
    "\n",
    "unemployment_df.dtypes\n",
    "\n",
    "unemployment_df['Unemployment Change'] = unemployment_df['Total Rate'].pct_change().round(4)\n",
    "unemployment_df.loc[0, 'Unemployment Change'] = 0\n",
    "\n",
    "unemployment_df.head(10)\n",
    "unemployment_df.to_csv(\"unemployment_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_df.dtypes\n",
    "sp500_df[\"Date\"] = pd.to_datetime(sp500_df[\"Date\"])\n",
    "sp500_df.dtypes\n",
    "\n",
    "sp500_df = sp500_df[(sp500_df[\"Day\"] == 1) & (sp500_df[\"Date\"] >= \"2005-03-01\")]\n",
    "sp500_df = sp500_df.reset_index(drop = True)\n",
    "\n",
    "sp500_df[\"Date\"] = sp500_df[\"Date\"].dt.strftime('%b %Y')\n",
    "sp500_df = sp500_df.drop(columns=['Day', 'Weekday', 'Week', 'Month', 'Year'])\n",
    "\n",
    "sp500_df[\"Close Change\"] = sp500_df[\"Close\"].pct_change().round(4)\n",
    "sp500_df.loc[0, \"Close Change\"] = 0\n",
    "sp500_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(sp500_df[['Date', 'Close']], unemployment_df, on='Date')\n",
    "\n",
    "univariate_stats = {}\n",
    "\n",
    "demographics = ['Total Rate', 'Male Rate', 'Female Rate', 'White Rate', 'Black Rate', 'Asian Rate', 'Hispanic Rate']\n",
    "for demographic in demographics:\n",
    "    stats = {\n",
    "        'mean': merged_data[demographic].mean(),\n",
    "        'median': merged_data[demographic].median(),\n",
    "        'std_dev': merged_data[demographic].std(),\n",
    "        'min': merged_data[demographic].min(),\n",
    "        'max': merged_data[demographic].max(),\n",
    "        'skewness': merged_data[demographic].skew(),\n",
    "        'kurtosis': merged_data[demographic].kurt()\n",
    "    }\n",
    "    univariate_stats[demographic] = stats\n",
    "\n",
    "sp500_stats = {\n",
    "    'mean': merged_data['Close'].mean(),\n",
    "    'median': merged_data['Close'].median(),\n",
    "    'std_dev': merged_data['Close'].std(),\n",
    "    'min': merged_data['Close'].min(),\n",
    "    'max': merged_data['Close'].max(),\n",
    "    'skewness': merged_data['Close'].skew(),\n",
    "    'kurtosis': merged_data['Close'].kurt()\n",
    "}\n",
    "\n",
    "univariate_stats['S&P 500'] = sp500_stats\n",
    "univariate_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code calculates the Pearson correlation between the S&P 500 closing price ('Close' column in merged_data) and each demographic variable listed in the demographics list. It stores each correlation value in a dictionary called correlations, then prints out the correlation coefficients to show how strongly each demographic variable is linearly related to the S&P 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = {}\n",
    "for demographic in demographics:\n",
    "    correlation = merged_data['Close'].corr(merged_data[demographic])\n",
    "    correlations[demographic] = correlation\n",
    "\n",
    "print(\"Correlation with S&P 500 Closing Price:\")\n",
    "for demographic, correlation in correlations.items():\n",
    "    print(f\"{demographic}: {correlation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs a simple linear regression analysis between the S&P 500 closing price ('Close') and each demographic variable in the demographics list. For each demographic, it fits an Ordinary Least Squares (OLS) model using statsmodels, stores the regression coefficients, p-values, and R-squared value in the regression_results dictionary, and then prints these statistics to summarize the strength, significance, and explanatory power of each demographic variable in predicting the S&P 500 closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = {}\n",
    "for demographic in demographics:\n",
    "    X = merged_data[demographic]\n",
    "    X = sm.add_constant(X)\n",
    "    y = merged_data['Close']\n",
    "    \n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    regression_results[demographic] = {\n",
    "        'coefficients': model.params,\n",
    "        'p_values': model.pvalues,\n",
    "        'r_squared': model.rsquared\n",
    "    }\n",
    "\n",
    "print(\"Regression Results:\")\n",
    "for demographic, results in regression_results.items():\n",
    "    print(f\"\\n{demographic}:\")\n",
    "    print(f\"  Coefficients: {results['coefficients']}\")\n",
    "    print(f\"  p-values: {results['p_values']}\")\n",
    "    print(f\"  R-squared: {results['r_squared']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code merges unemployment and S&P 500 datasets on the 'Date' column, then conducts an independent two-sample t-test (assuming unequal variances) to determine whether there is a statistically significant difference between the average male unemployment rate and the S&P 500 daily high values. It prints the t-statistic and p-value, and based on a significance level of 0.05, it states whether to reject or fail to reject the null hypothesis that the two means are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(unemployment_df, sp500_df, on='Date')\n",
    "\n",
    "unemployement = merged_df[\"Male Rate\"]\n",
    "sp500_high = merged_df[\"High\"]\n",
    "\n",
    "t_stat, p_value = ttest_ind(unemployement, sp500_high, equal_var=False)\n",
    "\n",
    "print(f\"T-Statistic: {t_stat:.4f}\")\n",
    "print(f\"P-Value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject H0: The average values are significantly different between unemployment and SP500 Highs.\")\n",
    "else:\n",
    "    print(\"Fail to reject H0: No significant difference found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code generates a scatter plot with a regression line to visualize the relationship between the male unemployment rate and the S&P 500 high price. It uses pink dots for the data points and a red line for the linear trend, adds labels and a title for clarity, and includes a grid to enhance readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.regplot(x=merged_df[\"Male Rate\"], y=merged_df[\"High\"], ci=None, scatter_kws={\"color\": \"pink\"}, line_kws={\"color\": \"red\"})\n",
    "plt.title(\"Relationship between Male Unemployment Rate and S&P 500 High\")\n",
    "plt.xlabel(\"Male Unemployment Rate (%)\")\n",
    "plt.ylabel(\"S&P 500 High Price\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs a Pearson correlation test to examine the linear relationship between the female unemployment rate and the S&P 500 high price. It calculates the correlation coefficient and associated p-value, then tests the null hypothesis that there is no correlation. Based on a 0.05 significance level, it determines whether the observed correlation is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coeff, p_value = pearsonr(merged_df[\"Female Rate\"], merged_df[\"High\"])\n",
    "\n",
    "print(f\"Correlation Coefficient: {corr_coeff:.4f}\")\n",
    "print(f\"P-Value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject H0: Significant correlation exists.\")\n",
    "else:\n",
    "    print(\"Fail to reject H0: No significant correlation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a dual-axis time series plot to visualize the relationship between the female unemployment rate and the S&P 500 high price over time. The left y-axis (in blue) shows the female unemployment rate, while the right y-axis (in red) displays the S&P 500 high. This allows for a clear comparison of their trends on the same timeline without overlapping scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"Date\"] = pd.to_datetime(merged_df[\"Date\"])\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Female Unemployment Rate (%)', color=color)\n",
    "ax1.plot(merged_df[\"Date\"], merged_df[\"Female Rate\"], color=color, label=\"Female Unemployment Rate\")\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax1.xaxis.set_major_locator(mdates.YearLocator(5))\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('S&P 500 High Price', color=color)\n",
    "ax2.plot(merged_df[\"Date\"], merged_df[\"High\"], color=color, label=\"S&P 500 High\")\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Female Unemployment Rate and S&P 500 High Over Time')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"SP500_Up\"] = (merged_df[\"Close Change\"] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code fits a logistic regression model to predict the binary outcome SP500_Up (e.g., whether the S&P 500 went up) using various demographic unemployment rates as predictors. It adds a constant term to the features for the intercept, uses statsmodels' Logit function to build the model, and prints a statistical summary of the fitted model, including coefficients, p-values, and goodness-of-fit metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = merged_df[[\"Male Rate\", \"Female Rate\", \"Teen Rate\", \"White Rate\", \"Black Rate\", \"Asian Rate\", \"Hispanic Rate\"]]\n",
    "target = merged_df[\"SP500_Up\"]\n",
    "\n",
    "features = sm.add_constant(features)\n",
    "\n",
    "logit_model = sm.Logit(target, features)\n",
    "result = logit_model.fit()\n",
    "\n",
    "print(result.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
